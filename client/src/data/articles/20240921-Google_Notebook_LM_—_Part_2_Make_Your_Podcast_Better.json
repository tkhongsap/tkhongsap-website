{
  "title": "Google Notebook LM ‚Äî Part 2: Make Your Podcast Better",
  "url": "https://medium.com/@kenji-onisuka/google-notebooklm-part-2-7baaacfb8bd8",
  "author": "Kenji",
  "publish_date": "Sep 21, 2024",
  "read_time": "4 min read",
  "claps": 51,
  "comments": 0,
  "content": "Google Notebook LM ‚Äî Part 2: Make Your Podcast Better\n\nHow to Use Better Inputs for Superior Podcast Results\n\nKenji\n\n51\n\nA few days ago, I started using Google NotebookLM. In my previous article, I mentioned that the most valuable feature was the ability to generate an audio podcast from the documents you upload. Whether it‚Äôs text, websites, PDFs, or markdown files, the tool creates a conversational podcast summarizing the content ‚Äî perfect for those who prefer learning through audio.\n\nüîó Read Part 1: Introduction to Google NotebookLM‚Äôs Podcast Feature\n\nThis feature continues to be incredibly useful for my learning and research. For example, before getting into a complex topic or paper, I upload the material into NotebookLM and generate an audio podcast to help process the information. These podcasts typically run between 7 to 12 minutes, making them great for quickly absorbing key ideas. If the subject requires deeper exploration, I still read the document in full.\n\nüîç Quick Note: Before discovering NotebookLM, I used platforms like OpenAI or Claude for text summarization. However, turning these summaries into podcasts has been a refreshing and efficient way to engage with content.\n\n‚ö†Ô∏è Input Quality Matters\n\nAs the saying goes, ‚Äúgarbage in, garbage out.‚Äù The quality of the document you upload directly affects the podcast quality that NotebookLM generates. While the tool handles simple text documents well, it may struggle with more complex files, such as financial reports or research papers that contain detailed tables.\n\nüìâ Example: If you upload a PDF of NVIDIA‚Äôs latest 10-Q filing (https://investor.nvidia.com/financial-info/sec-filings/default.aspx), you‚Äôll notice the document includes complicated tables like consolidated financial statements, cash flow statements, and balance sheets. Uploading the PDF file directly may lead to information loss in key details from the tables.\n\nü¶ô How LlamaParse Improves Results\n\nWhen dealing with complex PDFs, I highly recommend using LlamaParse. This tool, developed by LlamaCloud, is designed to extract and restructure data from PDFs into more manageable markdown files. LlamaParse is especially effective at handling documents with complex tables and formatting, ensuring the content is organized in a way that is more accessible for NotebookLM to process into a high-quality podcast.\n\nüí° Why This Matters: Although using LlamaParse adds an extra step, the improvement is worth the effort. For instance, I recently tested this with NVIDIA‚Äôs 10-Q filing. I created two podcasts‚Äîone from a markdown file generated by LlamaParse and another directly from the raw PDF. To me, the markdown-based podcast was noticeably clearer and more detailed.\n\nüíª How to Use LlamaParse\n\nLlamaParse is part of LlamaCloud, a hosted service that allows you to upload and parse documents. It is also accessible via API.\n\nüì• Steps to Get Started:\n\nüîó [Sign up for LlamaParse Beta Here]\n\nHere is a Python template for using LlamaParse:\n\nimport os\nfrom os import environ\nfrom os.path import join, splitext, basename\nfrom llama_parse import LlamaParse  # Replace with the actual parser you are using\nfrom dotenv import load_dotenv  # type: ignore\n\n# Load environment variables\nload_dotenv()\napi_key = environ.get(\"API_KEY_VARIABLE_NAME\")  # Set your environment variable for the API key\nprint(api_key)\n\n# Define your parsing instructions based on the specific content you are extracting\nparsing_instruction = \"\"\"\nYour parsing instructions go here.\nFor example, instruct to extract specific sections, omit certain elements, \nand specify how the content should be formatted (e.g., markdown, plain text).\n\"\"\"\n\n# Initialize the parser with the API key and desired output format\nparser = LlamaParse(\n    api_key=api_key,\n    result_type=\"OUTPUT_FORMAT\",  # Choose the desired format: \"markdown\", \"text\", etc.\n    parsing_instruction=parsing_instruction\n)\n\n# Define the file path to the input document\nfile_path = \"path_to_your_input_file.pdf\"\n\n# Load the document for parsing\ndocuments = parser.load_data(file_path)\n\n# Function to save the parsed documents into a single file in the specified output format\ndef save_combined_documents(documents, input_file, output_folder):\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    # Generate the output file name based on the input file name\n    base_name = splitext(basename(input_file))[0]  # Extracts the base name of the file\n    output_file_name = f\"{base_name}.OUTPUT_EXTENSION\"  # Change the extension accordingly\n    output_path = join(output_folder, output_file_name)\n\n    print(f\"Saving all documents to: {output_path}\")\n\n    # Combine all document texts into one string\n    combined_text = \"\\n\\n\".join([doc.text for doc in documents])\n\n    # Write the combined text to a single file\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(combined_text)\n\n    print(f\"All documents have been saved to {output_file_name}\")\n\n# Define the output folder and save the combined documents\noutput_folder = \"path_to_output_folder\"\nsave_combined_documents(documents\n\nFinal Note\n\nGoogle NotebookLM is a great tool for turning written content into podcasts, making it ideal for auditory learners. However, for complex documents, using LlamaParse is key to producing clearer, more detailed podcasts. By first converting files into markdown, you enhance both clarity and depth.\n\nI‚Äôm eager to see how these tools evolve and will keep using them in my workflow.\n\nIf you enjoyed this article, you might also like:\n\nGoogle Notebook LM: PodCast Feature\n\nI Don‚Äôt Know About This (Obviously I Was Under a Rock)\n\nmedium.com\n\nCursor AI: 3 Days In, and Here‚Äôs Why I‚Äôm Subscribing\n\nCursor AI Just Saved My Sanity üòÖ\n\nmedium.com\n\nCursor AI ‚Äî AI-Powered Coding Editor\n\nCoding Assistant: From Prompt to Project ‚Äî Coding Smarter, Not Harder\n\nmedium.com",
  "scraped_at": "2025-04-07 08:22:15"
}