{
  "title": "Stop AI Hallucinations: 4 Practical Tips for Beginners",
  "url": "https://medium.com/ai-unscripted/stop-ai-hallucinations-4-practical-tips-for-beginners-4d377dc405c8",
  "author": "Kenji",
  "publish_date": "Nov 10, 2024",
  "read_time": "3 min read",
  "claps": 47,
  "comments": 0,
  "content": "You\n highlighted\n\nYou\n highlighted\n\nYou\n highlighted\n\nMember-only story\n\nStop AI Hallucinations: 4 Practical Tips for Beginners\n\nSimple steps to make your AI interactions clear, accurate, and dependable\n\nKenji\n\nAI Unscripted\n\n47\n\nA\nI is powerful — but it’s far from perfect. When the line between insight and error blurs, these simple techniques bring clarity, accuracy, and trust back into the equation.\n\nIf you’ve ever used a Gen-AI tool and thought, “Wait, where did it get that information? Or that doesn’t look right.”, then you’ve probably encountered what we call a hallucination. It’s just making stuff up.\n\nHallucinations happen when AI generates information that isn’t accurate or supported by its training data.\n\nI use Gen-AI a little bit for my work, from analysis to programming, and there are a few steps that I use to reduce hallucinations, whether I’m writing simple prompts or setting up a long system prompt for an application.\n\nHere’s what works for me, and I think it can work for you too.\n\nWhy Does AI Hallucinate?\n\nFor now, AI doesn’t yet “think”. It predicts what to say based on patterns it has learned, but this process isn’t flawless. Here are a few common reasons behind AI hallucinations:\n\nThe good news? You can work around this with better prompts and system setups. Let’s talk about how.\n\n4 Tips to Stop Hallucinations\n\nThese tips are practical and easy to apply. They work whether you’re crafting a one-off prompt or programming a system prompt for an application. Each tip comes with examples so you can try it out yourself.\n\n1. Define Specific Prompts\n\nWhen you ask a vague question, the AI has no choice but to guess what you mean. It does not read your mind, it reads your prompts. So, clear, detailed prompts make it easier for the model to give you accurate answers.\n\nTry it yourself:\n\nWhen programming, use this idea to guide system prompts. For example:\n\n2. Ask for Sources\n\nIf the AI is providing factual information, request citations or references. This ensures the model bases its output on trustworthy data, and it makes it easier for you to verify the response.\n\nTry it yourself:\n\nIn system design, add a rule: “If unsure, state: ‘I do not have the information.’”\n\n3. Use Constraints to Keep AI Focused\n\nAI models are designed to answer almost anything. That’s not always a good thing. Limit the scope of the response to reduce the likelihood of hallucinations.\n\nTry it yourself:\n\nThis keeps the AI grounded in areas where it is most reliable.\n\n4. Provide Feedback to Improve Outputs\n\nWhen the AI generates something incorrect, don’t just move on. Correct it and reframe your prompt. This helps refine the responses over time and ensures better results in iterative tasks.\n\nTry it yourself:\n\nThe Key Takeaway\n\nAvoiding hallucinations isn’t about knowing all the answers — it’s about asking the right questions and setting clear boundaries. Whether you’re interacting with AI for fun or deploying it in serious applications, these tips help you stay in control.",
  "scraped_at": "2025-04-07 08:41:31"
}