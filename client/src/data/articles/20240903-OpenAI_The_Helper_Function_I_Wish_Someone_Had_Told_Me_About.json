{
  "title": "OpenAI The Helper Function I Wish Someone Had Told Me About",
  "url": "https://medium.com/@kenji-onisuka/the-helper-function-i-wish-someone-had-told-me-about-653fb75e3d4b",
  "author": "Kenji",
  "publish_date": "Sep 3, 2024",
  "read_time": "2 min read",
  "claps": 61,
  "comments": 0,
  "content": "OpenAI The Helper Function I Wish Someone Had Told Me About\n\nIntegrating OpenAI Assistant API with Streamlit\n\nKenji\n\n61\n\nI wish someone had told me about this helper function when I first started building apps and doing quick POCs on Streamlit. Integrating OpenAI Assistant with Streamlit can be complex, especially for beginners. It took me a few tries before I developed this helper function, which I now reuse frequently. It has become an essential tool in my development toolkit, and Iâ€™m sharing it to help others overcome similar challenges.\n\nKey Benefits of the Helper Function:\n\nThe helper function:\n\nimport openai\nimport streamlit as st\nfrom openai import OpenAI\n\napi_key = st.secrets[\"OPENAI_API_KEY\"]\nclient = OpenAI(api_key=api_key)\n\ndef wait_on_run(run, thread_id):\n    while run.status == 'queued' or run.status == 'in_progress':\n        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)\n\ndef display_thread_messages(messages):\n    message_texts = []\n    for thread_message in messages.data[::-1]:\n        message_texts.append(thread_message.content[0].text.value)\n    return \"\\n\\n\".join(message_texts)\n\ndef generate_response(user_message, assistant_id):\n    if 'thread_id' not in st.session_state:\n        thread = client.beta.threads.create()\n        st.session_state['thread_id'] = thread.id\n    thread_id = st.session_state['thread_id']\n\n    try:\n        message = client.beta.threads.messages.create(\n            thread_id=thread_id,\n            role='user',\n            content=user_message)\n\n        run = client.beta.threads.runs.create(\n            thread_id=thread_id,\n            assistant_id=assistant_id)\n\n        with st.spinner(\"Generating answer...\"):\n            wait_on_run(run, thread_id)\n\n        messages = client.beta.threads.messages.list(\n            thread_id=thread_id,\n            order='asc',\n            after=message.id)\n\n        return display_thread_messages(messages)\n    except Exception as e:\n        st.error(f\"An error occurred: {str(e)}\")\n        return \"Error generating response. Please try again.\"\n\nWhy This Approach Matters\n\nThis streamlined integration of Streamlit and OpenAI offers several key advantages:\n\nIf you are working on both OpenAI and Streamlit, I encourage you to try this approach in your next project. It provides a solid foundation for building interactive AI applications without getting bogged down in complex integration details. Remember, the goal is to create powerful AI applications while maintaining simplicity in your code.\n\nHappy coding!\n\n#StreamlitAI #OpenAIIntegration #AIDevTools #PythonCoding #ChatbotDevelopment #TechInnovation #AIApplications",
  "scraped_at": "2025-04-07 08:29:06"
}