{
  "title": "Llama 4 Herd: My First Look at Meta’s Promising Scout Model",
  "url": "https://medium.com/@kenji-onisuka/llama-4-herd-my-first-look-at-metas-promising-scout-model-e429d31ebd3c",
  "author": "Kenji",
  "publish_date": null,
  "read_time": "3 min read",
  "claps": 0,
  "comments": 0,
  "cover_image_url": "https://miro.medium.com/v2/resize:fit:875/0*jeAZ-nKInVjeRL6R",
  "content": "Member-only story\n\nLlama 4 Herd: My First Look at Meta’s Promising Scout Model\n\nKenji\n\nNo, I haven’t downloaded it yet. But I will. This week. And I can’t wait.\n\nMeta just dropped something big. Llama 4, the latest model family in the Llama ecosystem, comes with three flavors — Scout, Maverick, and the upcoming Behemoth. And even though I haven’t installed Scout yet, the specs alone are enough to get me thinking about what’s coming next in the open-source model world.\n\nHere’s what caught my attention — and why I’ll be downloading the Scout model first.\n\nLlama 4 Scout: Small Model, Huge Capabilities\n\nLet’s get one thing out of the way: calling Scout “small” is a stretch. It has 109 billion total parameters, with 17 billion active, and runs on a mixture-of-experts (MoE) architecture using 16 experts.\n\nWhat really stands out, though, is its 10 million token context window.\n\nThat’s not just a leap; it’s a canyon-sized gap between Scout and most previous models, including many that were until recently considered top-tier.\n\nEven more impressive? Its performance on long-context tasks and multimodal reasoning (yes, this model handles video and images too).\n\nOpen Weights, Real Access\n\nMeta has released open weights for Scout and Maverick.\n\nIt’s a welcome move toward openness in a time when many frontier models are being locked behind closed ecosystems.\n\nThe Maverick model, by the way, is no slouch either — it beats GPT-4o and Gemini 2.0 Flash on cost-performance and reasoning tasks. But I’m starting with Scout, mainly because of its potential to run on a single GPU and its unique combination of size, speed, and scope.\n\nOne Big Caveat: Licensing\n\nOf course, there is the licensing issue. As with Llama 3, Meta’s license still comes with some restrictions, particularly for large-scale commercial users.\n\nAnd yes, attribution is required if you build on top of it. But it's still a significant opportunity for individual developers or research teams.\n\nIn short: Llama 4 Scout looks like the best “small” model we’ve seen yet. And I’m excited to take it for a spin. I’ll report back with real-world insights once I’ve tested it.\n\nIf you’ve already tried it — or plan to — let me know what you’re working on. These models are here, and they’re moving fast.",
  "scraped_at": "2025-04-08 10:51:48"
}