{
  "title": "My Experience with OpenWebUI API Access: Overcoming Common Integration Challenges",
  "url": "https://medium.com/@kenji-onisuka/my-experience-with-openwebui-api-access-overcoming-common-integration-challenges-3026aba44378",
  "author": "Kenji",
  "publish_date": "Sep 17, 2024",
  "read_time": "5 min read",
  "claps": 11,
  "comments": 1,
  "cover_image_url": "https://miro.medium.com/v2/resize:fit:700/0*Jy0lyvB_h5FBKgsp",
  "content": "My Experience with OpenWebUI API Access: Overcoming Common Integration Challenges\n\nTips and Solutions for Solving Common OpenWebUI API Access Issues\n\nKenji\n\n11\n\n1\n\nToday, I worked on an OpenWebUI API project, and it didn’t go as smoothly as I’d hoped. Being new to the platform and with limited documentation, what seemed like a simple task took longer than expected. I faced a few issues, including:\n\nI thought it would be helpful to share some of the key obstacles I encountered and the solutions that worked for me. Hopefully, this will serve as a quick reference for anyone else navigating these challenges.\n\n1. Authentication Issues: Getting It Right\n\nOne of the first hurdles I encountered was authentication errors like {\"detail\":\"Not authenticated\"}. These errors were mainly due to missing tokens or incorrect headers.\n\nSolution\n\nTo fix the authentication issues, I focused on:\n\nHere’s the code I used to resolve this issue:\n\nimport requests\nimport sys\n\n# ANSI escape codes for blue bold text and reset\nBLUE_BOLD = \"\\033[1;34m\"\nRESET = \"\\033[0m\"\n\ndef print_highlight(message):\n    print(f\"\\n{BLUE_BOLD}{message}{RESET}\")\n\n# Authenticate and get the token\nauth_url = \"http://your-server-url/api/v1/auths/signin\"\nauth_payload = {\n    \"email\": \"your-email@example.com\",\n    \"password\": \"your_password\"\n}\n\ntry:\n    auth_response = requests.post(auth_url, json=auth_payload)\n    auth_response.raise_for_status()  # Check if authentication fails\n    token = auth_response.json().get(\"token\")\n    \n    if not token:\n        raise ValueError(\"Token not found in response\")\n    \n    print_highlight(f\"Authentication successful, Token: {token}\")\n\n    # Use this token in headers for subsequent requests\n    headers = {\n        \"Authorization\": f\"Bearer {token}\",\n        \"Content-Type\": \"application/json\"\n    }\n\nexcept requests.RequestException as e:\n    print_highlight(f\"Authentication request failed: {e}\")\n    sys.exit(1)\nexcept ValueError as e:\n    print_highlight(f\"Authentication failed: {e}\")\n    sys.exit(1)\n\nFollowing these steps ensures proper headers and tokens, helping you avoid authentication errors and interact smoothly with the OpenWebUI API.\n\n2. Referencing Uploaded Documents in API Calls\n\nAnother challenge was referencing documents in the model’s knowledge base for Retrieval Augmented Generation (RAG). Without clear steps, it wasn't easy to retrieve document references.\n\nSolution\n\nHere’s how I successfully retrieved document IDs:\n\nHere’s the code I used to handle document referencing:\n\nimport requests\nimport sys\nimport json\n\n# ANSI escape codes for blue bold text and reset\nBLUE_BOLD = \"\\033[1;34m\"\nRESET = \"\\033[0m\"\n\ndef print_highlight(message):\n    print(f\"\\n{BLUE_BOLD}{message}{RESET}\")\n\n# Step 1: Authenticate and get the token\nauth_url = \"http://your-server-url/api/v1/auths/signin\"\nauth_payload = {\n    \"email\": \"your-email@example.com\",\n    \"password\": \"your_password\"\n}\n\ntry:\n    auth_response = requests.post(auth_url, json=auth_payload)\n    auth_response.raise_for_status()\n    token = auth_response.json().get(\"token\")\n    if not token:\n        raise ValueError(\"Token not found in response\")\n    print_highlight(f\"Authentication successful, Token: {token}\")\n\n    # Define headers for subsequent requests\n    headers = {\n        \"Authorization\": f\"Bearer {token}\"\n    }\n\nexcept requests.RequestException as e:\n    print_highlight(f\"Authentication request failed: {e}\")\n    sys.exit(1)\nexcept ValueError as e:\n    print_highlight(f\"Authentication failed: {e}\")\n    sys.exit(1)\n\n# Step 2: Fetch available models and extract document IDs from the knowledge section\ndef get_available_models(base_url, headers):\n    models_url = f\"{base_url}/api/models\"\n    try:\n        response = requests.get(models_url, headers=headers)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        print_highlight(f\"Error fetching available models: {e}\")\n        return None\n\nbase_url = \"http://your-server-url\"\navailable_models = get_available_models(base_url, headers)\n\nif available_models and 'data' in available_models:\n    print_highlight(\"Knowledge section from the models:\")\n    for model in available_models['data']:\n        meta = model.get('info', {}).get('meta', {})\n        knowledge = meta.get('knowledge', [])\n        if knowledge:\n            print_highlight(f\"Document IDs for model '{model.get('id')}':\")\n            print(json.dumps(knowledge, indent=2))  # Print the document references (IDs)\n        else:\n            print_highlight(f\"No knowledge section found for model: {model.get('id')}\")\nelse:\n    print_highlight(\"Unable to fetch available models\")\n\nFollowing these steps, you can easily identify and reference document IDs from the model’s knowledge base for RAG queries.\n\n3. Handling Model Completion and Streaming Responses\n\nWhen working with interactive chats, the OpenWebUI API supports streaming, allowing me to receive responses in chunks. This is perfect for real-time applications but can be tricky to manage if not set up correctly.\n\nSolution\n\nHere’s what worked for me:\n\nHere’s the code I used to create an interactive chat interface:\n\nimport requests\nimport uuid\nimport sys\nimport json\nimport readline  # For better input handling\nfrom rich import print as rprint\nfrom rich.console import Console\nfrom rich.prompt import Prompt\nfrom rich.progress import Progress\n\n# ANSI escape codes for text colors\nBLUE = \"\\033[1;34m\"\nGREEN = \"\\033[1;32m\"\nRED = \"\\033[1;31m\"\nRESET = \"\\033[0m\"\n\nconsole = Console()\n\ndef print_highlight(message, color=BLUE):\n    print(f\"\\n{color}{message}{RESET}\")\n\ndef get_available_models(base_url, headers):\n    models_url = f\"{base_url}/api/models\"\n    try:\n        with Progress() as progress:\n            task = progress.add_task(\"[cyan]Fetching available models...\", total=None)\n            response = requests.get(models_url, headers=headers)\n            progress.update(task, completed=100)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as e:\n        print_highlight(f\"Error fetching available models: {e}\", RED)\n        return None\n\ndef select_model(available_models):\n    rprint(\"[bold]Available models:[/bold]\")\n    for i, model in enumerate(available_models['data'], 1):\n        rprint(f\"{i}. {model['id']}\")\n    \n    choice = Prompt.ask(\"Select a model\", choices=[str(i) for i in range(1, len(available_models['data'])+1)])\n    return available_models['data'][int(choice)-1]['id']\n\ndef process_stream_response(response):\n    full_response = \"\"\n    for line in response.iter_lines():\n        if line:\n            try:\n                json_response = json.loads(line.decode('utf-8').split('data: ')[1])\n                if 'choices' in json_response and json_response['choices']:\n                    content = json_response['choices'][0].get('delta', {}).get('content', '')\n                    if content:\n                        print(f\"{BLUE}{content}{RESET}\", end='', flush=True)\n                        full_response += content\n                elif 'usage' in json_response:\n                    print(f\"\\n\\n{GREEN}Usage: {json_response['usage']}{RESET}\")\n            except json.JSONDecodeError:\n                if b'data: [DONE]' in line:\n                    continue  # Skip the [DONE] message\n                print(f\"{RED}Error decoding JSON: {line}{RESET}\")\n    print()  # Add a newline at the end\n    return full_response\n\ndef interactive_chat(base_url, headers, model):\n    print_highlight(f\"Starting interactive chat with model: {model}\")\n    print_highlight(\"Type 'exit' to end the conversation.\")\n    \n    session_id = str(uuid.uuid4())\n    messages = []\n\n    while True:\n        user_input = Prompt.ask(f\"\\n{GREEN}You{RESET}\")\n        if user_input.lower() == 'exit':\n            break\n\n        messages.append({\"role\": \"user\", \"content\": user_input})\n        chat_payload = {\n            \"stream\": True,\n            \"model\": model,\n            \"stream_options\": {\"include_usage\": True},\n            \"messages\": messages,\n            \"session_id\": session_id,\n            \"chat_id\": \"\",\n            \"id\": str(uuid.uuid4())\n        }\n\n        print(f\"\\n{BLUE}AI{RESET}: \", end='', flush=True)\n        try:\n            with requests.post(f\"{base_url}/api/chat/completions\", json=chat_payload, headers=headers, stream=True) as chat_response:\n                chat_response.raise_for_status()\n                ai_response = process_stream_response(chat_response)\n                messages.append({\"role\": \"assistant\", \"content\": ai_response})\n        except requests.RequestException as e:\n            print_highlight(f\"Error: {e}\", RED)\n\ndef main():\n    # Step 1: Authenticate and get the token\n    base_url = \"http://your-server-url\"\n    auth_url = f\"{base_url}/api/v1/auths/signin\"\n    auth_payload = {\n        \"email\": \"your-email@example.com\",\n        \"password\": \"your_password\"\n    }\n    try:\n        with Progress() as progress:\n            task = progress.add_task(\"[cyan]Authenticating...\", total=None)\n            auth_response = requests.post(auth_url, json=auth_payload)\n            progress.update(task, completed=100)\n        auth_response.raise_for_status()\n        token = auth_response.json().get(\"token\")\n        if not token:\n            raise ValueError(\"Token not found in response\")\n        print_highlight(\"Authentication successful\", GREEN)\n    except requests.RequestException as e:\n        print_highlight(f\"Authentication request failed: {e}\", RED)\n        sys.exit(1)\n    except ValueError as e:\n        print_highlight(f\"Authentication failed: {e}\", RED)\n        sys.exit(1)\n\n    # Define headers after getting the token\n    headers = {\n        \"Authorization\": f\"Bearer {token}\"\n    }\n\n    # Step 2: Fetch available models\n    available_models = get_available_models(base_url, headers)\n    if not available_models:\n        print_highlight(\"Unable to fetch available models. Exiting.\", RED)\n        sys.exit(1)\n\n    # Step 3: Select model\n    model_name = select_model(available_models)\n\n    # Step 4: Start interactive chat\n    interactive_chat(base_url, headers, model_name)\n\nif __name__ == \"__main__\":\n    main()\n\nEnabling streaming and real-time data processing ensures efficient model completions, delivering a smooth user experience in chat applications.\n\nConclusion\n\nOpenWebUI’s API offers powerful tools for leveraging models and retrieving documents, but I found that careful attention to authentication, document handling, and managing API streams was essential. The solutions I shared worked for me, helping to navigate these challenges. By following these practices, you should be able to integrate OpenWebUI smoothly and confidently tackle any hiccups along the way.\n\nReferences",
  "scraped_at": "2025-04-07 09:11:58"
}